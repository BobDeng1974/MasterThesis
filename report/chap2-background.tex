%included in thesis.tex,


\chapter{Background}
This chapter will try to outline the basics needed to understand this report. Mathematical
knowledge are crucial to understand the principles used in robot navigation and decision
making. 


\section{Mathematical description and modelling of a Snake robot}


\section{State-of-the-Art Literature study}


\subsection{Distance Measurement Principles}
There are several ways to measure distance. Most principles measures the distance
indirectly, i.e. by processing the reflected signal of either light-, radio- or
sound waves. Laser range finders (LRFs) and sonar are examples of this way to measure
distance. 

When looking at Laser Range Finder, there are 3 techniques for determining the distance,
\emph{optical triangulation}, \emph{pulse Time-of-Flight} and \emph{frequency modulated
continuous wave} (FMCW). \cite{laser-ranging-critical-review}

\subsubsection{Optical Triangulation}
Optical triangulation is performed by using a light source and a placed at known distance
from each other. This distance is called the baseline. This is a triangulation setup which
allows for the calculation of the intersection point between the lines. 

\begin{figure}[htbp]
    \caption{Optical Triangulation setup}
    \label{fig:optical-triangulation}
\end{figure}
***Lag figur***

This method has some fundamental limits. \cite{laser-ranging-critical-review} 

This technique is mostly used when the measured distance is short and the need for
extremely precise measurements. For example digitalization of 3D objects.


\subsubsection{Pulsed Time-of-Flight}
The laser light which is emitted are amplitude modulated, and the received signal is
compared to the emitted signal and the phase delay is measured. This is then directly
proportional to the distance the light traveled. 


\subsubsection{Frequency Modulated Continuous Wave}



\subsection{2D/3D Sensors}



\subsubsection{Laser Range Finders}




\subsubsection{Time-of-Flight Cameras}




\subsection{Map Data Representation}
The representation of sensor data is important for the functionality of the robot. This is
dependant on the amount of processing power and capacity that is available at the robot.
The area which the robot is to map is also of great importance when choosing the
representation. There are a number of representations that are tried out, and each one has its good and
bad abilities. 

The major representation methods which is used in literature are summarized in the below
sections.


\subsubsection{Occupancy Grid Maps}
Occupancy grid maps are widely used in robotic mapping, mostly because of it is simple to
implement and use. This method assumes that the robots pose is known. This method was
developed by Elfes and Moravec in the mid 1980s, \cite{elfes}, \cite{moravec}.



\subsubsection{Topological Maps}
Topological maps represents the sensed world in the form of predefined nodes and links
between them. Each node has a set of attributes, like length, links to doors etc. This is
a compact way to express the world and is much more computationally effective with larger
maps than the occupancy grid maps might be.

The problem with this representation is that it needs a lot of input a priori. The
operator creates and inputs the map to the robot, which uses this map for navigation. The
largest challenge with this is to make the robot aware of where it is. It needs in some
way to recognize its surroundings, and match it to the a priori map.


\subsubsection{Hybrid Approaches}




\subsection{Sensor Fusion Techniques}



\subsubsection{Interpolation Techniques}



\subsubsection{Probabilistic Techniques}





\subsection{Real World Applications}



